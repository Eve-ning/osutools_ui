---
title: "documentation"
author: "eve-ning"
date: "5/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(knitr)
library(magrittr)
```

# Introduction

Keep it short, make a simulator that plays VSRG

# THE PLAN

1. Create an interface for **VSRG Charts**
2. Create an interface for the **Player**
3. Create an environment where both of those **interact**

  We want to be able to test out the parameters

4. Simulate the plays and train the machine according to players

# Goal

We want to be able to simulate virtual player's playthroughs regardless of if it's accurate.
Making it accurate to reality would be the next goal.

Our expected output would be something like:

```{r echo=F}
ex.offsets = c(1,2,2,3,4)
ex.keys = c(0,1,2,0,0)
ex.acc = c(0.9,0.3,0.4,0.7,0.1)

ex = cbind(offsets = ex.offsets, keys = ex.keys, 'predicted accuracy' = ex.acc)

kable(ex,caption = "Expected output")
rm(ex.offsets, ex.keys, ex.acc, ex)
```

# Accuracy or Deviation

Let's say the player hits the note, **50ms early**, how do we translate that into accuracy? 

We will have to map it to a function, which "grades" the deviation, similar to VSRG Judgements.

**However**, this deviation holds more meaning than a mapped deviation, as there is no *universal function* to translate deviation into accuracy. Hence, we will focus on deviation instead of accuracy.

## Defining Deviation

When we ask players on what makes them hit a note accurately, it usually narrows down to the most common answers:

- Player skill
- Map difficulty

We need to understand that **Player skill** is totally independent of **Map difficulty**. Hence we must enforce that:

**Map difficulty should not be dynamically calculated from player performance**

# Layout

## Resource Downloading
This will be done in Python, no exceptions

## Parsing
This can be done in R or Python, I'm leaning more towards R since it'll make the workflow easier to handle in one IDE

## Simulating
This can be done in R or Python, similarly, I'm leaning towards R due to performance issues when it comes to `reticulate`

## Detailing
This should be done in R due to simulated DataFrames being easier to work in R than PyPandas.

## Plotting
Using R through ggplot2

## Analysing correlations
Using RShiny, we should implement a UI that we can tweak to form a good simulation.

## Machine Learning
Depends on if we want to use this, we can somehow integrate machine learning in here to polish the results, rather than eyeballing it.

**

# Input

*Notice: all the following code are pseudocode, they are not actually ran*

The input would be 2 different datasets.

**Map** `type, column, offset`
**Player Replay** `column, offset, deviation`

Note that there are no uniquely identifying columns in both of these datasets.

## Grouping Datasets

We will create a working unique index for both of these through offset.

```
map.groupby(by=offset)
replay.groupby(by=offset)
```
It should look something like this
```
Map
Column | Type    | Offset
-------+---------+--------
[1,2,3]|[N,N,LNH]|   1
           ...

Replay
Column |   Dev   | Offset
-------+---------+--------
[1,2,3]|[4,3,-1] |   1
           ...
```

### Offset Grouping for Players

There may be queries on why offsets should be grouped. The main reason for grouping lies later in the document, where **Grace Periods** and **Column Categorization** occurs.

## Identifying the model

Next, we establish what the model should perform and what variables can we provide it with.

Essentially, the model should be:

$$f(column, type) = dev$$






